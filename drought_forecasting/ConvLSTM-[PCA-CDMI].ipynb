{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q torch-summary\n!pip install -q patchify","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-25T11:44:36.548187Z","iopub.execute_input":"2022-07-25T11:44:36.549144Z","iopub.status.idle":"2022-07-25T11:44:57.840011Z","shell.execute_reply.started":"2022-07-25T11:44:36.549048Z","shell.execute_reply":"2022-07-25T11:44:57.839059Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# import the necessary packages\nimport math\nimport random\nimport rasterio\nimport gc\ngc.collect()\nimport pickle\nimport numpy as np\n\n# import splitfolders\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom patchify import patchify, unpatchify\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import Tensor\nfrom torchmetrics import Metric\nfrom torchsummary import summary\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader, Sampler, BatchSampler, random_split\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning import Trainer, LightningDataModule\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:44:57.842224Z","iopub.execute_input":"2022-07-25T11:44:57.842885Z","iopub.status.idle":"2022-07-25T11:45:06.073631Z","shell.execute_reply.started":"2022-07-25T11:44:57.842837Z","shell.execute_reply":"2022-07-25T11:45:06.072228Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Config():\n    def __init__(self):\n        # Dataset/Dataloaders params\n        self.years = ['2016','2017','2018','2019','2020','2021','2022']\n        self.months = ['1','2','3','4']\n        self.base_dir = '../input/cdmipcamergeddataset/CDMI-PCA/CDMI_'\n        self.patch_size = 128\n        self.batch_size = 12\n        self.num_workers = 2\n        \n        # Model params\n        self.input_dim  = 1              #Number of channels of input tensor.\n        self.hidden_dim = 64             #Number of channels of hidden state.\n        self.kernel_size = 5             #Size of the convolutional kernel.\n        self.num_layers = 1              #Number of ConvLSTM layers\n        \n        \n        # Training params\n        self.learning_rate = 1e-4\n        self.weight_decay = 1e-5\n        self.exec_mode = None\n        self.num_epochs = 100\n\n        \n        self.seed = 26012022\n        self.generator = torch.Generator().manual_seed(self.seed)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:45:06.075464Z","iopub.execute_input":"2022-07-25T11:45:06.076699Z","iopub.status.idle":"2022-07-25T11:45:06.089691Z","shell.execute_reply.started":"2022-07-25T11:45:06.076653Z","shell.execute_reply":"2022-07-25T11:45:06.088867Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:45:06.092239Z","iopub.execute_input":"2022-07-25T11:45:06.092810Z","iopub.status.idle":"2022-07-25T11:45:06.176457Z","shell.execute_reply.started":"2022-07-25T11:45:06.092755Z","shell.execute_reply":"2022-07-25T11:45:06.175225Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# def get_CDMI_chronologically(base_dir, years, months):\n#     cdmi_paths = [base_dir+j+'_'+i+'.tif' for i in years for j in months]\n#     gc.collect()\n#     return cdmi_paths\n\n# def read_rasters(base_dir, years, months):\n#     cdmi_paths = get_CDMI_chronologically(base_dir, years, months)[:34]\n#     cdmi_stack = np.stack([rasterio.open(f).read() for f in cdmi_paths], axis=1)\n#     cdmi_stack[np.isnan(cdmi_stack)] = 0\n#     gc.collect()\n#     return cdmi_stack[:,:,:4352,:5120]  # (1, 34, 4352, 5120)\n\n# def patchify_images(base_dir, years, months, patch_size):\n#     cdmi_stack = read_rasters(base_dir, years, months)\n#     patchified_images = patchify(cdmi_stack, (1, 34, patch_size, patch_size), step=patch_size).squeeze()  #(17, 20, 128, 128))\n#     data_cube = patchified_images.reshape((-1, 34, patch_size, patch_size))\n#     np.save('./data_cube.npy', data_cube)\n#     gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:45:06.182930Z","iopub.execute_input":"2022-07-25T11:45:06.183427Z","iopub.status.idle":"2022-07-25T11:45:06.192579Z","shell.execute_reply.started":"2022-07-25T11:45:06.183363Z","shell.execute_reply":"2022-07-25T11:45:06.191660Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# patchify_images(config.base_dir, config.years, config.months, config.patch_size)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:45:06.197230Z","iopub.execute_input":"2022-07-25T11:45:06.199000Z","iopub.status.idle":"2022-07-25T11:45:06.204948Z","shell.execute_reply.started":"2022-07-25T11:45:06.198939Z","shell.execute_reply":"2022-07-25T11:45:06.203945Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class CDMIDataset (Dataset):\n    def __init__(self, base_dir, years, months, patch_size):  \n        \n        self.base_dir = base_dir\n        self.years = years\n        self.months = months\n        self.patch_size = patch_size\n        self.patchified_cdmi = np.load('../input/datacube256-6m/data_cube.npy')\n        gc.collect()\n#         self.patchified_cdmi = patchify_images(self.base_dir, self.years, self.months, self.patch_size)\n        \n    def __len__(self):\n        return len(self.patchified_cdmi)\n\n        \n    def __getitem__(self, idx):\n        x = self.patchified_cdmi[idx]      \n        # numpy array --> torch tensor\n        x_tensor = torch.tensor(x[None], dtype=torch.float32)\n        return x_tensor   ","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:45:06.207632Z","iopub.execute_input":"2022-07-25T11:45:06.207970Z","iopub.status.idle":"2022-07-25T11:45:06.222916Z","shell.execute_reply.started":"2022-07-25T11:45:06.207938Z","shell.execute_reply":"2022-07-25T11:45:06.222223Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class CDMIDataModule(LightningDataModule):\n    def __init__(self, config):\n        self.config = config\n\n        \n    def setup(self, stage=None):\n        cdmi_dataset = CDMIDataset (self.config.base_dir, self.config.years,\n                                    self.config.months, self.config.patch_size)\n        self.cdmi_train, self.cdmi_val = random_split(cdmi_dataset,\n                                                      [math.floor(0.9*len(cdmi_dataset)),\n                                                       math.ceil(0.1*len(cdmi_dataset))],\n                                                       generator=self.config.generator) \n    \n        \n    def train_dataloader(self):\n        return DataLoader(self.cdmi_train, batch_size=self.config.batch_size,\n                          num_workers=self.config.num_workers)\n\n    \n    def val_dataloader(self):\n        return DataLoader(self.cdmi_val, batch_size=3,\n                          shuffle=False, num_workers=self.config.num_workers,drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:45:06.223926Z","iopub.execute_input":"2022-07-25T11:45:06.224745Z","iopub.status.idle":"2022-07-25T11:45:06.234494Z","shell.execute_reply.started":"2022-07-25T11:45:06.224708Z","shell.execute_reply":"2022-07-25T11:45:06.233766Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class ConvLSTMCell(nn.Module):\n    def __init__(self, input_dim, hidden_dim, kernel_size):\n        super(ConvLSTMCell, self).__init__()  \n\n        self.input_dim  = input_dim      #Number of channels of input tensor.\n        self.hidden_dim = hidden_dim     #Number of channels of hidden state.\n        self.kernel_size = kernel_size   #Size of the convolutional kernel.\n#         self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n\n        \n        self.Gates = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n                               out_channels=4 * self.hidden_dim,\n                               kernel_size=self.kernel_size,\n                               padding=self.kernel_size//2)\n\n\n    def forward(self, x, h_prev, c_prev):\n\n        combined_conv = self.Gates(torch.cat([x, h_prev], dim=1))\n\n        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n        i = torch.sigmoid(cc_i)\n        f = torch.sigmoid(cc_f)\n        o = torch.sigmoid(cc_o)\n        g = torch.relu(cc_g)\n\n        c_cur = f * c_prev + i * g    # Current Cell output\n        h_cur = o * torch.relu(c_cur) # Current Hidden State\n\n        return h_cur, c_cur","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:45:06.235533Z","iopub.execute_input":"2022-07-25T11:45:06.236408Z","iopub.status.idle":"2022-07-25T11:45:06.252622Z","shell.execute_reply.started":"2022-07-25T11:45:06.236371Z","shell.execute_reply":"2022-07-25T11:45:06.251901Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class ConvLSTM(nn.Module):\n    \n    def __init__(self, input_dim, hidden_dim, kernel_size):\n        super(ConvLSTM, self).__init__()\n\n        self.input_dim  = input_dim      #Number of channels of input tensor.\n        self.hidden_dim = hidden_dim     #Number of channels of hidden state.\n        self.kernel_size = kernel_size   #Size of the convolutional kernel.\n       \n\n        # We will unroll this over time steps\n        self.convLSTMcell = ConvLSTMCell(input_dim=self.input_dim,\n                                          hidden_dim=self.hidden_dim,\n                                          kernel_size=self.kernel_size)\n\n        \n    def forward(self, x):\n\n        # Get the dimensions\n        batch_size, _, seq_len, height, width = x.size() # shape(B, C, S, H, W)\n        # Initialize output\n        output = torch.zeros(batch_size, self.hidden_dim, seq_len, height, width, device=device)\n        # Initialize Hidden State\n        H = torch.zeros(batch_size, self.hidden_dim, height, width, device=device)\n        # Initialize Cell Input\n        C = torch.zeros(batch_size, self.hidden_dim, height, width, device=device)\n\n        # Unroll over time steps\n        for time_step in range(seq_len):\n            H, C = self.convLSTMcell(x[:,:,time_step], H, C)\n            output[:,:,time_step] = H\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:45:06.257417Z","iopub.execute_input":"2022-07-25T11:45:06.257803Z","iopub.status.idle":"2022-07-25T11:45:06.273564Z","shell.execute_reply.started":"2022-07-25T11:45:06.257770Z","shell.execute_reply":"2022-07-25T11:45:06.272875Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n\n    def __init__(self, config):\n        super(Seq2Seq, self).__init__()\n \n        self.sequential = nn.Sequential()\n        self.config = config\n               \n\n        # Add First layer (Different in_channels than the rest)\n        self.sequential.add_module(\n            \"convlstm1\", ConvLSTM(input_dim=self.config.input_dim,\n                                  hidden_dim=self.config.hidden_dim,\n                                  kernel_size=self.config.kernel_size))\n        \n\n        self.sequential.add_module(\n            \"batchnorm1\", nn.BatchNorm3d(num_features=self.config.hidden_dim)) \n\n        # Add rest of the layers\n        for l in range(2, self.config.num_layers+1):\n            self.sequential.add_module(\n                f\"convlstm{l}\", ConvLSTM(input_dim=self.config.hidden_dim,\n                                         hidden_dim=self.config.hidden_dim,\n                                         kernel_size=self.config.kernel_size))\n                \n            self.sequential.add_module(\n                f\"batchnorm{l}\", nn.BatchNorm3d(num_features=self.config.hidden_dim)\n                ) \n\n        # Add Convolutional Layer to predict output frame\n        self.conv = nn.Conv2d(in_channels=self.config.hidden_dim,\n                              out_channels=self.config.input_dim,\n                              kernel_size=self.config.kernel_size,\n                              padding = self.config.kernel_size//2)\n                \n        self.sigmoid = nn.Sigmoid()\n        \n        # initialize weights\n        self._initialize_weights()\n                \n\n    def forward(self, x):\n\n        # Forward propagation through all the layers\n        output = self.sequential(x)\n        # Return only the last output frame\n        output = self.conv(output[:,:,-1])\n        # Pass it through a sigmoid\n        next_frame = self.sigmoid(output)\n                \n        return next_frame\n    \n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in', nonlinearity='relu')\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm3d): \n                m.weight.data.fill_(1)\n                m.bias.data.zero_()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:45:06.279521Z","iopub.execute_input":"2022-07-25T11:45:06.282052Z","iopub.status.idle":"2022-07-25T11:45:06.302139Z","shell.execute_reply.started":"2022-07-25T11:45:06.282015Z","shell.execute_reply":"2022-07-25T11:45:06.300892Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def collate(batch):\n    batch = batch.to(device) \n    # Randomly pick 14 frames as input, 15th frame is target\n    rand = np.random.randint(6,40)                     \n    return batch[:,:,rand-6:rand], batch[:,:, rand] \n\ndef collate_test(batch):\n    # Last 10 frames are target\n    target = batch[:,:,30:]                          \n    batch = batch.to(device)                          \n    return batch, target.squeeze()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:45:06.307099Z","iopub.execute_input":"2022-07-25T11:45:06.309985Z","iopub.status.idle":"2022-07-25T11:45:06.318143Z","shell.execute_reply.started":"2022-07-25T11:45:06.309949Z","shell.execute_reply":"2022-07-25T11:45:06.317406Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# The input video frames are grayscale, thus single channel\nmodel = Seq2Seq(config).to(device)\noptimizer = torch.optim.Adam(model.parameters(),\n                             lr=config.learning_rate,\n                             weight_decay=config.weight_decay)\n\ncriterion = nn.MSELoss()                    \n# summary(model, (1, 4, 256, 256)) #sanity check","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:45:06.322961Z","iopub.execute_input":"2022-07-25T11:45:06.325803Z","iopub.status.idle":"2022-07-25T11:45:10.727165Z","shell.execute_reply.started":"2022-07-25T11:45:06.325675Z","shell.execute_reply":"2022-07-25T11:45:10.726352Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"dm = CDMIDataModule(config)\ndm.setup() \n\nfor epoch in range(1, config.num_epochs+1):\n    \n    train_loss = 0                                                 \n    model.train()   \n    \n    for batch  in dm.train_dataloader():  \n        x, y = collate(batch)\n        \n        optimizer.zero_grad()\n        output = model(x) \n        loss = criterion(output, y)  \n        loss.backward()                                            \n        optimizer.step()                                               \n        train_loss += loss.item()                                 \n    train_loss /= len(dm.train_dataloader().dataset) \n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    val_loss = 0                                                 \n    model.eval()                                                   \n    with torch.no_grad():                                          \n        for batch  in dm.val_dataloader():\n            x, y = collate(batch)\n            \n            output = model(x)                                   \n            loss = criterion(output, y)   \n            val_loss += loss.item()                                \n    val_loss /= len(dm.val_dataloader().dataset) \n    torch.cuda.empty_cache()\n    gc.collect()\n\n    print(\"Epoch:{} Training Loss:{:.2f} Validation Loss:{:.2f}\\n\".format(\n        epoch, train_loss, val_loss))\ntorch.save(model.state_dict(), './model.pt')","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:47:16.594876Z","iopub.execute_input":"2022-07-18T08:47:16.595396Z","iopub.status.idle":"2022-07-18T08:48:14.800193Z","shell.execute_reply.started":"2022-07-18T08:47:16.595359Z","shell.execute_reply":"2022-07-18T08:48:14.798825Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check Model's outputs","metadata":{}},{"cell_type":"code","source":"#Load the saved model\nmodel.load_state_dict(torch.load('../input/convlstm6m6ts10e/model.pt'))\nmodel.eval()\ndm = CDMIDataModule(config)\ndm.setup() ","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:45:52.932555Z","iopub.execute_input":"2022-07-25T11:45:52.932910Z","iopub.status.idle":"2022-07-25T11:46:30.029724Z","shell.execute_reply.started":"2022-07-25T11:45:52.932879Z","shell.execute_reply":"2022-07-25T11:46:30.028941Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#Get a batch\nbatch = next(iter(dm.val_dataloader()))\nbatch, target = collate_test(batch) #torch.Size([10, 1, 28, 256, 256]) #torch.Size([10, 1, 18, 256, 256])\n\n# Initialize output sequence\noutput = np.zeros(target.shape, dtype=np.float32) \ntarget = target.cpu().detach().numpy()\n# target[target== 0] = np.nan\n# output[output== 0] = np.nan\n\nfor timestep in range(target.shape[1]):\n    input = batch[:,:,timestep:timestep+6] \n#     output[:,timestep]= model(input).squeeze(1).cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T12:16:28.173936Z","iopub.execute_input":"2022-07-25T12:16:28.174302Z","iopub.status.idle":"2022-07-25T12:16:30.202074Z","shell.execute_reply.started":"2022-07-25T12:16:28.174271Z","shell.execute_reply":"2022-07-25T12:16:30.200881Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize = (20,10)) \nax[0].imshow(target[2,8], cmap='gray') #(3, 30, 128, 128)\nax[1].imshow(output[2,8], cmap='gray') #(3, 30, 128, 128)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T08:29:00.738229Z","iopub.execute_input":"2022-07-19T08:29:00.738738Z","iopub.status.idle":"2022-07-19T08:29:01.339226Z","shell.execute_reply.started":"2022-07-19T08:29:00.738691Z","shell.execute_reply":"2022-07-19T08:29:01.337615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Forecasting","metadata":{}},{"cell_type":"code","source":"# Load data for forecasting\nforecasting_cdmi = np.load('../input/foreceasting-data/data_cube.npy') #(340, 6, 256, 256)\npred_data = torch.tensor(forecasting_cdmi, dtype=torch.float32)\npred_data = pred_data.unsqueeze(1).to(device) ","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:57:21.536029Z","iopub.execute_input":"2022-07-25T11:57:21.536692Z","iopub.status.idle":"2022-07-25T11:57:23.412534Z","shell.execute_reply.started":"2022-07-25T11:57:21.536654Z","shell.execute_reply":"2022-07-25T11:57:23.410844Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Initialize output sequence\n# output = np.zeros((340, 1, 256, 256), dtype=np.float32) \nAllarrays = []\npatch=0\nfor i in range(int(pred_data.shape[0]/10)):\n    output = model(pred_data[patch:patch+10,...]).squeeze(1).cpu().detach().numpy()\n    Allarrays.append(output)\n    patch+=10\n\nOutput = np.concatenate(Allarrays, axis=0, dtype=np.float32)  #(340, 256, 256)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T12:33:38.740823Z","iopub.execute_input":"2022-07-25T12:33:38.741199Z","iopub.status.idle":"2022-07-25T12:33:55.125797Z","shell.execute_reply.started":"2022-07-25T12:33:38.741149Z","shell.execute_reply":"2022-07-25T12:33:55.124915Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"plt.imshow(Output[300], cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2022-07-25T12:36:51.845545Z","iopub.execute_input":"2022-07-25T12:36:51.846010Z","iopub.status.idle":"2022-07-25T12:36:52.031461Z","shell.execute_reply.started":"2022-07-25T12:36:51.845975Z","shell.execute_reply":"2022-07-25T12:36:52.029617Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# reconstruct the prediction for Zambia\nOutput_reshaped = Output.reshape((17, 20, 256, 256))\nrecon_CDMI = unpatchify(Output_reshaped, (4352,5120))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T12:45:24.074437Z","iopub.execute_input":"2022-07-25T12:45:24.074814Z","iopub.status.idle":"2022-07-25T12:45:24.140265Z","shell.execute_reply.started":"2022-07-25T12:45:24.074782Z","shell.execute_reply":"2022-07-25T12:45:24.139418Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"plt.imshow(recon_CDMI, cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2022-07-25T12:45:50.498292Z","iopub.execute_input":"2022-07-25T12:45:50.498656Z","iopub.status.idle":"2022-07-25T12:45:51.879649Z","shell.execute_reply.started":"2022-07-25T12:45:50.498623Z","shell.execute_reply":"2022-07-25T12:45:51.877234Z"},"trusted":true},"execution_count":69,"outputs":[]}]}